<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>turk-chat-web</title>
    <style>
        body {
            background-color: darkgrey;
            width: 440px;
        }
        #status {
            padding: 10px;
            color: white;
            width: 420px;
        }
        .listening {
            background-color: blue;
        }
        .recording {
            background-color: red;
        }
        .stopped {
            background-color: grey;
        }
        
        /* button styling */
        button {
            padding: 10px 20px;
            font-size: 16px;
            color: white;
            background-color: #007bff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
    
        button:hover {
            background-color: #0056b3;
        }
    
        .message {
        margin-bottom: 10px;
        padding: 5px;
        border-radius: 5px;
        }
    
    .system-message {
        background-color: lightgrey;
        }
    
    .user-message {
        background-color: lightblue;
        text-align: right;
        }
    
    .assistant-message {
        background-color: lightgreen;
        }
    
    #messages {
        background-color: grey;    
        width: 420px;
        }
    
    .scrollable {
        max-height: 300px; /* Adjust height as needed */
        overflow-y: scroll;
        border: 1px solid #ccc; /* Just for visibility */
        padding: 10px;
      }
    
      #controls {
        padding: 10px;
      }
    
    </style>
</head>
<body>

    <div id="controls" align="center">
    <button id="startButton" onclick="startRecording()">Start Listening</button>
    </div>
    <hr //>
    <div id="status" class="stopped">Status: Stopped</div>
    <canvas id="vuMeter"></canvas>
    <hr //>
    <div id="messages" class="scrollable">&nbsp;</div>
    <hr //>
    <div id="log">&nbsp;</div>


<script>
    let audioContext;
    let isRecording = false;
    let isAboveThreshold = false;
    let ringBuffer = [];
    let ringBufferHead = 0;
    let startMarker = 0;
    let endMarker = 0;
    let endPersistCounter = 0;
    let startTime = 0;
    const END_PERSIST_PERIOD = 10; // How long to ignore silence when determining end of audio
    const BUFFER_SIZE = 4096;
    const PRE_ROLL = BUFFER_SIZE * 3; // Amount of preroll before the threshold is crossed
    const SAMPLE_RATE = 48000; // or use audioContext.sampleRate
    const THRESHOLD = 0.1;
    const BUFFER_DURATION = 60; // seconds
    const MAX_RING_BUFFER_LENGTH = SAMPLE_RATE * BUFFER_DURATION; // Total samples for the duration
    const ENDPOINT = window.location.href + 'upload'
    const statusDiv = document.getElementById('status');

    const RETRY_TIMEOUT = 1000 // Keep checking for responses at this frequency if first check failed
    const RESPONSE_DELAY = 3000 // How long to wait before checking for a response after submission

    function initAudioContext() {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
    }

    function startRecording() {
        if (!audioContext) {
            initAudioContext();
        }

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                isRecording = true;
                let microphone = audioContext.createMediaStreamSource(stream);
                let scriptProcessor = audioContext.createScriptProcessor(BUFFER_SIZE, 1, 1);
                microphone.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                scriptProcessor.onaudioprocess = processAudio;
                updateStatus("Listening...");
            }).catch(err => {
                console.error("Error accessing microphone", err);
            });
    }

    function processAudio(audioProcessingEvent) {
        if (!isRecording) return;

        let inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
        let sum = 0;

        for (let i = 0; i < inputData.length; ++i) {
            sum += inputData[i] * inputData[i];
            ringBuffer[ringBufferHead] = inputData[i]; // Save data to ring buffer
            ringBufferHead = (ringBufferHead + 1) % MAX_RING_BUFFER_LENGTH; // Circular increment
        }

        let volume = Math.sqrt(sum / inputData.length);
        detectSound(volume);
    }

    function detectSound(volume) {
        if (volume > THRESHOLD && !isAboveThreshold) {
            isAboveThreshold = true;
            // Dynamic start marker with preroll to ensure the start isn't clipped
            startMarker = (ringBufferHead + MAX_RING_BUFFER_LENGTH - PRE_ROLL) % MAX_RING_BUFFER_LENGTH;
            startTime = Date.now();
            updateStatus("Sound detected...");
        } else if (volume < THRESHOLD && isAboveThreshold) {
            if (endPersistCounter >= END_PERSIST_PERIOD) {
                isAboveThreshold = false;
                // Mark the end of the sound event at the current head position
                endMarker = ringBufferHead;
                let length = (endMarker - startMarker + MAX_RING_BUFFER_LENGTH) % MAX_RING_BUFFER_LENGTH;
                let audioData = new Float32Array(length);

                // Extract the audio data from the ring buffer
                for (let i = 0; i < length; i++) {
                    audioData[i] = ringBuffer[(startMarker + i) % MAX_RING_BUFFER_LENGTH];
                }

                let audioBuffer = audioContext.createBuffer(1, audioData.length, SAMPLE_RATE);
                audioBuffer.copyToChannel(audioData, 0);

                convertToWav(audioBuffer, startTime);
                updateStatus("Silence detected, processing...");

                // Maybe pause listening here

                endPersistCounter = 0;
            } else {
                endPersistCounter++;
            }
        }
    }

    function convertToWav(audioBuffer, label) {
        // Assuming 16-bit PCM WAV
        let numChannels = audioBuffer.numberOfChannels;
        let numSamples = audioBuffer.length;
        let buffer = new ArrayBuffer(44 + numSamples * 2 * numChannels);
        let view = new DataView(buffer);

        // Writing the WAV container
        // RIFF header
        writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + numSamples * 2, true); // File size
        writeString(view, 8, 'WAVE');
        // fmt subchunk (audio format details)
        writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true); // SubChunk1Size (16 for PCM)
        view.setUint16(20, 1, true); // Audio format (1 for PCM)
        view.setUint16(22, numChannels, true); // NumChannels
        view.setUint32(24, SAMPLE_RATE, true); // SampleRate
        view.setUint32(28, SAMPLE_RATE * numChannels * 2, true); // ByteRate
        view.setUint16(32, numChannels * 2, true); // BlockAlign
        view.setUint16(34, 16, true); // BitsPerSample
        // data subchunk (the sound data itself)
        writeString(view, 36, 'data');
        view.setUint32(40, numSamples * 2, true); // SubChunk2Size

        // Write the PCM audio data
        let index = 44;
        let volume = 1;
        for (let i = 0; i < numSamples; i++) {
            view.setInt16(index, audioBuffer.getChannelData(0)[i] * (0x7FFF * volume), true);
            index += 2;
        }

        let blob = new Blob([view], { type: 'audio/wav' });

        // Create FormData and append the file
        let formData = new FormData();
        formData.append("audio", blob, label + '.wav');
        
        // POST the form data to the Flask server
        fetch(ENDPOINT, {
            method: 'POST',
            body: formData
        })
        .then(response => response.json())
        .then(data => {
            console.log('Success:', data);
            updateStatus('File uploaded successfully!');

            loadAndPlayMP3(`${label}`.substring(0,10) + '.mp3');
            loadAndDisplayChatLog('joanne.json');

        })
        .catch((error) => {
            console.error('Error:', error);
            updateStatus('Failed to upload file.');
        });
    }

    function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }

    function updateStatus(message) {
        statusDiv.innerText = message;
        statusDiv.style.backgroundColor = isRecording ? "green" : "grey";
    }

    function loadAndPlayMP3(mp3_filename) {
    let hasPlayed = false;
    let attempts = 0;
    let audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let analyser = audioContext.createAnalyser();

    // Function to update UI after playback
    function updateUIAfterPlayback() {
        // Update UI here
        document.getElementById('status').textContent = 'Playback finished';
        console.log('Playback finished');
        
        // Maybe resume listening here
        
    }

    const drawVUMeter = () => {
        requestAnimationFrame(drawVUMeter); // Continuously loop
        let dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray); // Get frequency data

        // Use the frequency data to draw VU meter on canvas
        let canvas = document.getElementById('vuMeter');
        let ctx = canvas.getContext('2d');

        // Clear previous drawing
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Example drawing code for VU meter (customize as needed)
        let barWidth = (canvas.width / dataArray.length);
        let barHeight;
        let x = 0;
        for(let i = 0; i < dataArray.length; i++) {
            barHeight = dataArray[i]/2;
            ctx.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
            ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

            x += barWidth + 1;
        }
    };

    const tryFetch = () => {
        fetch(mp3_filename)
            .then(response => {
                if(response.ok) return response.blob();
                throw new Error('File not found');
            })
            .then(blob => {
                let audioSrc = audioContext.createMediaElementSource(new Audio(URL.createObjectURL(blob)));
                audioSrc.connect(analyser);
                analyser.connect(audioContext.destination);

                audioSrc.mediaElement.play();
                hasPlayed = true;
                drawVUMeter();

                // Add event listener for when the audio finishes playing
                audioSrc.mediaElement.addEventListener('ended', updateUIAfterPlayback);
            })
            .catch(error => {
                console.error('Fetch failed', error);
            });
    };

    setTimeout(() => {
        tryFetch();
        let interval = setInterval(() => {
            if(!hasPlayed && attempts < 120) {
                tryFetch();
                attempts++;
            } else {
                clearInterval(interval);
            }
        }, RETRY_TIMEOUT);
    }, RESPONSE_DELAY);
}

async function loadAndDisplayChatLog(message_log_filename) {
    try {
        // Fetch the chat log from the server
        const response = await fetch(message_log_filename);
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status} (${message_log_filename})`);
        }

        // Parse the JSON data
        const chatLog = await response.json();

        // Format the chat log into HTML
        let formattedHtml = '';
        chatLog.forEach(entry => {
            switch (entry.role) {
                case 'system':
                    // formattedHtml += `<div class="message system-message">${entry.content}</div>`;
                    break;
                case 'user':
                    formattedHtml += `<div class="message user-message">${entry.content}</div>`;
                    break;
                case 'assistant':
                    formattedHtml += `<div class="message assistant-message">${entry.content}</div>`;
                    break;
                default:
                    formattedHtml += `<div class="message">${entry.content}</div>`;
            }
        });

        // Replace the contents of the 'messages' div with the formatted HTML
        document.getElementById('messages').innerHTML = formattedHtml;

    } catch (error) {
        console.error('Failed to load chat log:', error);
    }
}

</script>
</body>
</html>
