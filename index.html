<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Speech Detector</title>
<style>
    body {
        background-color: darkgrey;
    }
    #status {
        padding: 10px;
        color: white;
        width: 420px;
    }
    .listening {
        background-color: blue;
    }
    .recording {
        background-color: red;
    }
    .stopped {
        background-color: grey;
    }
    
    /* button styling */
    button {
        padding: 10px 20px;
        font-size: 16px;
        color: white;
        background-color: #007bff;
        border: none;
        border-radius: 5px;
        cursor: pointer;
    }

    button:hover {
        background-color: #0056b3;
    }

    .message {
    margin-bottom: 10px;
    padding: 5px;
    border-radius: 5px;
    }

.system-message {
    background-color: lightgrey;
    }

.user-message {
    background-color: lightblue;
    text-align: right;
    }

.assistant-message {
    background-color: lightgreen;
    }

#messages {
    background-color: grey;    
    width: 420px;
    }

.scrollable {
    max-height: 300px; /* Adjust height as needed */
    overflow-y: scroll;
    border: 1px solid #ccc; /* Just for visibility */
    padding: 10px;
  }

</style>
</head>
<body>
<h1>Web Converse</h1>
<button id="startButton">Start Listening</button>
<hr //>
<div id="status" class="stopped">Status: Stopped</div>
<canvas id="vuMeter"></canvas>
<hr //>
<div id="messages" class="scrollable">&nbsp;</div>
<script>
// Set up necessary variables and constants
let isRecording = false;
let mediaRecorder;
let audioChunks = [];
let audioContext;
let analyser;
let dataArray, bufferLength;
const THRESHOLD = 5; // Adjust based on your needs, log volume to find a good value
const SPEECH_END_COUNT = 20; // Count of chunks below threshold to signify end of speech
let belowThresholdCount = 0;
let isAboveThreshold = false;
let startTimestamp;
const statusDiv = document.getElementById('status');
let started = false; // Track if audio has started
let RETRY_TIMEOUT = 1000 // Keep checking for responses at this frequency if first check failed
let RESPONSE_DELAY = 3000 // How long to wait before checking for a response after submission
// let ENDPOINT = "https://localhost:5000/upload"
let ENDPOINT = window.location.href + 'upload'

document.getElementById('startButton').addEventListener('click', () => {
    if(!started) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser(); // Make sure the analyser is part of the audio context
        started = true;
        initializeMedia();
    } else {
        // audioContext.resume();
        stopRecording()
        document.getElementById('startButton').innerText = 'Resume Listening'
    }
});
loadAndDisplayChatLog('joanne.json');

document.addEventListener("DOMContentLoaded", function() {
  var element = document.getElementById("scrollableDiv");
  element.scrollTop = element.scrollHeight;
});

function updateScroll(){
    var element = document.getElementById("content");
    element.scrollTop = element.scrollHeight;
}

function initializeMedia() {
    navigator.mediaDevices.getUserMedia({audio: true})
    .then(stream => {
        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser); // Connect source to analyser
        bufferLength = analyser.frequencyBinCount;
        dataArray = new Uint8Array(bufferLength);

        // Media Recorder setup
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.onstop = handleStop;
        mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
        };
        startRecording();
    })
    .catch(err => {
        console.error('Error accessing media devices.', err);
        statusDiv.innerText = "Error: Cannot access microphone.";
        statusDiv.classList.add("stopped");
    });
}

function startRecording() {
    isRecording = true;
    audioChunks = [];
    mediaRecorder.start();
    monitorAudio();
    statusDiv.innerText = "Status: Listening";
    statusDiv.classList.remove("stopped");
    statusDiv.classList.add("listening");
    document.getElementById('startButton').innerText = 'Stop Listening'
}

function stopRecording() {
    isRecording = false;
    mediaRecorder.stop(); // Triggers the onstop event
    statusDiv.innerText = "Status: Stopped, sending data.";
    statusDiv.classList.remove("listening");
    statusDiv.classList.add("stopped");
}

function monitorAudio() {
    if (!isRecording) return;

    analyser.getByteTimeDomainData(dataArray);
    let sum = 0;
    for(let i = 0; i < bufferLength; i++) {
        sum += (dataArray[i] - 128) * (dataArray[i] - 128); // Centering the RMS calculation around 128 (midpoint of Uint8)
    }
    let volume = Math.sqrt(sum / bufferLength);
    console.log(`Volume: ${volume}, Threshold: ${THRESHOLD}`); // Log for debugging

    if (volume > THRESHOLD) {
        if (!isAboveThreshold) {
            console.log("Audio detected");
            startTimestamp = Date.now();
            isAboveThreshold = true;
            statusDiv.innerText = "Status: Recording";
            statusDiv.classList.remove("listening");
            statusDiv.classList.add("recording");
        }
        belowThresholdCount = 0;
    } else {
        if (isAboveThreshold) {
            belowThresholdCount += 1;
            if (belowThresholdCount > SPEECH_END_COUNT) {
                console.log("End of speech detected");
                stopRecording();
                isAboveThreshold = false;
            }
        }
    }
    requestAnimationFrame(monitorAudio);
}

function handleStop() {
    const blob = new Blob(audioChunks, { 'type' : 'audio/wav; codecs=opus' });
    sendDataToServer(blob, startTimestamp);
    statusDiv.innerText = "Status: Processing...";
    statusDiv.classList.remove("recording");
    statusDiv.classList.add("stopped");
    document.getElementById('startButton').disabled = true
}

function sendDataToServer(blob, startTime) {
    const formData = new FormData();
    wav_filename = `${startTime}`.substring(0,10) + '.wav'
    formData.append("audio", blob, wav_filename);

    // Adjust URL to your server's endpoint
    fetch(ENDPOINT, {
        method: "POST",
        body: formData
    })
    .then(response => response.json())
    .then(data => {
        console.log(data);
        statusDiv.innerText = "Status: Complete";
        loadAndPlayMP3(`${startTime}`.substring(0,10) + '.mp3');
        loadAndDisplayChatLog('joanne.json');
        document.getElementById('startButton').disabled = false
    })
    .catch(error => {
        console.error("Error sending data:", error);
        statusDiv.innerText = "Error: Could not send data";
    });
}

function loadAndPlayMP3(mp3_filename) {
    let hasPlayed = false;
    let attempts = 0;
    let audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let analyser = audioContext.createAnalyser();

    // Function to update UI after playback
    function updateUIAfterPlayback() {
        // Update UI here
        document.getElementById('status').textContent = 'Playback finished';
        console.log('Playback finished');
        startRecording();
    }

    const drawVUMeter = () => {
        requestAnimationFrame(drawVUMeter); // Continuously loop
        let dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray); // Get frequency data

        // Use the frequency data to draw VU meter on canvas
        let canvas = document.getElementById('vuMeter');
        let ctx = canvas.getContext('2d');

        // Clear previous drawing
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Example drawing code for VU meter (customize as needed)
        let barWidth = (canvas.width / dataArray.length);
        let barHeight;
        let x = 0;
        for(let i = 0; i < dataArray.length; i++) {
            barHeight = dataArray[i]/2;
            ctx.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
            ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

            x += barWidth + 1;
        }
    };

    const tryFetch = () => {
        fetch(mp3_filename)
            .then(response => {
                if(response.ok) return response.blob();
                throw new Error('File not found');
            })
            .then(blob => {
                let audioSrc = audioContext.createMediaElementSource(new Audio(URL.createObjectURL(blob)));
                audioSrc.connect(analyser);
                analyser.connect(audioContext.destination);

                audioSrc.mediaElement.play();
                hasPlayed = true;
                drawVUMeter();

                // Add event listener for when the audio finishes playing
                audioSrc.mediaElement.addEventListener('ended', updateUIAfterPlayback);
            })
            .catch(error => {
                console.error('Fetch failed', error);
            });
    };

    setTimeout(() => {
        tryFetch();
        let interval = setInterval(() => {
            if(!hasPlayed && attempts < 120) {
                tryFetch();
                attempts++;
            } else {
                clearInterval(interval);
            }
        }, RETRY_TIMEOUT);
    }, RESPONSE_DELAY);
}

async function loadAndDisplayChatLog(message_log_filename) {
    try {
        // Fetch the chat log from the server
        const response = await fetch(message_log_filename);
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status} (${message_log_filename})`);
        }

        // Parse the JSON data
        const chatLog = await response.json();

        // Format the chat log into HTML
        let formattedHtml = '';
        chatLog.forEach(entry => {
            switch (entry.role) {
                case 'system':
                    // formattedHtml += `<div class="message system-message">${entry.content}</div>`;
                    break;
                case 'user':
                    formattedHtml += `<div class="message user-message">${entry.content}</div>`;
                    break;
                case 'assistant':
                    formattedHtml += `<div class="message assistant-message">${entry.content}</div>`;
                    break;
                default:
                    formattedHtml += `<div class="message">${entry.content}</div>`;
            }
        });

        // Replace the contents of the 'messages' div with the formatted HTML
        document.getElementById('messages').innerHTML = formattedHtml;
        updateScroll();

    } catch (error) {
        console.error('Failed to load chat log:', error);
    }
}

</script>
</body>
</html>
