<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>turk-chat-web</title>
    <style>
        body {
            background-color: darkgrey;
            width: 440px;
        }
        #status {
            padding: 10px;
            color: white;
            width: 420px;
        }
        .listening {
            background-color: blue;
        }
        .recording {
            background-color: red;
        }
        .stopped {
            background-color: grey;
        }
        
        /* button styling */
        button {
            padding: 10px 20px;
            font-size: 16px;
            color: white;
            background-color: #007bff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
    
        button:hover {
            background-color: #0056b3;
        }
    
        .message {
        margin-bottom: 10px;
        padding: 5px;
        border-radius: 5px;
        }
    
    .system-message {
        background-color: lightgrey;
        }
    
    .user-message {
        background-color: lightblue;
        text-align: right;
        }
    
    .assistant-message {
        background-color: lightgreen;
        }
    
    #messages {
        background-color: grey;    
        width: 420px;
        }
    
    #engine-log {
        font-size: xx-small;
    }
    
    .scrollable {
        max-height: 300px; /* Adjust height as needed */
        overflow-y: scroll;
        border: 1px solid #ccc; /* Just for visibility */
        padding: 10px;
      }
    
      #controls {
        padding: 10px;
      }
    
    </style>
</head>
<body>

    <div id="controls" align="center">
    <button id="startButton" onclick="startRecording()">Start Listening</button>
    </div>
    <div id="status" class="stopped">Status: Stopped</div>
    <canvas id="vuMeter"></canvas>
    <div id="messages" class="scrollable">&nbsp;</div>
    <div id="engine-log">&nbsp;</div>


<script>
let audioContext;
let isRecording = false;
let isProcessing = false; // Flag to indicate audio processing is ongoing
let isAboveThreshold = false;
let ringBuffer = [];
let ringBufferHead = 0;
let startMarker = 0;
let endMarker = 0;
let endPersistCounter = 0;
let startTime = 0;
const END_PERSIST_PERIOD = 10; // How long to ignore silence when determining end of audio
const BUFFER_SIZE = 4096;
const PRE_ROLL = BUFFER_SIZE * 3; // Amount of preroll before the threshold is crossed
const SAMPLE_RATE = 48000; // or use audioContext.sampleRate
const THRESHOLD = 0.1;
const BUFFER_DURATION = 60; // seconds
const MAX_RING_BUFFER_LENGTH = SAMPLE_RATE * BUFFER_DURATION; // Total samples for the duration
const ENDPOINT = window.location.href + 'upload'
const statusDiv = document.getElementById('status');

const RETRY_TIMEOUT = 1000 // Keep checking for responses at this frequency if first check failed
const RESPONSE_DELAY = 5000 // How long to wait before checking for a response after submission

const MESSAGE_LOG_FILENAME = 'messages.json'
const ENGINE_LOG_FILENAME = 'turk_flask.log'
const ENGINE_LOG_LINES_LIMIT = 20 // How much of the engine log tail to show

let manuallyStopped = false

window.addEventListener('load', function() {

    loadAndDisplayChatLog(MESSAGE_LOG_FILENAME);
    loadAndDisplayEngineLog(ENGINE_LOG_FILENAME);

});


function initAudioContext() {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
}

function startRecording() {
    if (!audioContext) {
        initAudioContext();
    }

    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            isRecording = true;
            let microphone = audioContext.createMediaStreamSource(stream);
            let scriptProcessor = audioContext.createScriptProcessor(BUFFER_SIZE, 1, 1);
            microphone.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);
            scriptProcessor.onaudioprocess = processAudio;
            updateStatus("Listening...");

            document.getElementById('startButton').style.display = 'none';

        }).catch(err => {
            console.error("Error accessing microphone", err);
        });
}

function processAudio(audioProcessingEvent) {
    if (!isRecording || isProcessing) return; // Don't process new audio if currently processing or not recording

    let inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
    let sum = 0;

    for (let i = 0; i < inputData.length; ++i) {
        sum += inputData[i] * inputData[i];
        ringBuffer[ringBufferHead] = inputData[i]; // Save data to ring buffer
        ringBufferHead = (ringBufferHead + 1) % MAX_RING_BUFFER_LENGTH; // Circular increment
    }

    let volume = Math.sqrt(sum / inputData.length);
    detectSound(volume);
}

function detectSound(volume) {
    if (volume > THRESHOLD && !isAboveThreshold) {
        isAboveThreshold = true;
        startMarker = (ringBufferHead + MAX_RING_BUFFER_LENGTH - PRE_ROLL) % MAX_RING_BUFFER_LENGTH;
        startTime = Date.now();
        updateStatus("Sound detected...");
    } else if (volume < THRESHOLD && isAboveThreshold) {
        if (endPersistCounter >= END_PERSIST_PERIOD) {
            isAboveThreshold = false;
            endMarker = ringBufferHead;
            let length = (endMarker - startMarker + MAX_RING_BUFFER_LENGTH) % MAX_RING_BUFFER_LENGTH;
            let audioData = new Float32Array(length);

            for (let i = 0; i < length; i++) {
                audioData[i] = ringBuffer[(startMarker + i) % MAX_RING_BUFFER_LENGTH];
            }

            let audioBuffer = audioContext.createBuffer(1, audioData.length, SAMPLE_RATE);
            audioBuffer.copyToChannel(audioData, 0);

            isRecording = false; 
            isProcessing = true;
            convertToWav(audioBuffer, startTime);
            updateStatus("Silence detected, processing...");

            endPersistCounter = 0;
        } else {
            endPersistCounter++;
        }
    }
}

function convertToWav(audioBuffer, label) {
    let numChannels = audioBuffer.numberOfChannels;
    let numSamples = audioBuffer.length;
    let buffer = new ArrayBuffer(44 + numSamples * 2 * numChannels);
    let view = new DataView(buffer);

    // Writing the WAV container
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + numSamples * 2, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, SAMPLE_RATE, true);
    view.setUint32(28, SAMPLE_RATE * numChannels * 2, true);
    view.setUint16(32, numChannels * 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, numSamples * 2, true);

    let index = 44;
    let volume = 1;
    for (let i = 0; i < numSamples; i++) {
        view.setInt16(index, audioBuffer.getChannelData(0)[i] * (0x7FFF * volume), true);
        index += 2;
    }

    let blob = new Blob([view], { type: 'audio/wav' });

    let formData = new FormData();
    formData.append("audio", blob, label + '.wav');
    
    fetch(ENDPOINT, {
        method: 'POST',
        body: formData
    })
    .then(response => response.json())
    .then(data => {
        console.log('Success:', data);
        updateStatus('File uploaded successfully!');

        loadAndPlayMP3(`${label}`.substring(0,10) + '.mp3').then(() => {
            // After playback is complete, resume listening if not manually stopped
            if (!manuallyStopped) { // Ensure there's a mechanism to handle manual stop
                isRecording = true;
                isProcessing = false;
            }
            updateStatus("Listening...");
        });

    })
    .catch((error) => {
        console.error('Error:', error);
        updateStatus('Failed to upload file.');
        isRecording = true;
        isProcessing = false;
    });
}

function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}

function updateStatus(message) {
    statusDiv.innerText = message;
    statusDiv.style.backgroundColor = isRecording ? "green" : "grey";
}

function loadAndPlayMP3(mp3_filename) {
    return new Promise((resolve, reject) => {
        let hasPlayed = false;
        let attempts = 0;
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let analyser = audioContext.createAnalyser();

        function updateUIAfterPlayback() {
            document.getElementById('status').textContent = 'Playback finished';
            console.log('Playback finished');
            resolve(); // Resolve the promise indicating the MP3 has finished playing
        }

        const drawVUMeter = () => {
            requestAnimationFrame(drawVUMeter);
            let dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);

            let canvas = document.getElementById('vuMeter');
            let ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            let barWidth = (canvas.width / dataArray.length);
            let barHeight;
            let x = 0;
            for(let i = 0; i < dataArray.length; i++) {
                barHeight = dataArray[i]/2;
                ctx.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
                ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

                x += barWidth + 1;
            }
        };

        const tryFetch = () => {
            fetch(mp3_filename)
                .then(response => {
                    if(response.ok) return response.blob();
                    throw new Error('File not found');
                })
                .then(blob => {
                    let audioSrc = audioContext.createMediaElementSource(new Audio(URL.createObjectURL(blob)));
                    audioSrc.connect(analyser);
                    analyser.connect(audioContext.destination);

                    audioSrc.mediaElement.play();
                    hasPlayed = true;
                    drawVUMeter();

                    audioSrc.mediaElement.addEventListener('ended', updateUIAfterPlayback);

                    loadAndDisplayChatLog(MESSAGE_LOG_FILENAME)
                    loadAndDisplayEngineLog(ENGINE_LOG_FILENAME)
                    
                })
                .catch(error => {
                    console.error('Fetch failed', error);
                    reject(error);
                });
        };

        setTimeout(() => {
            tryFetch();
            let interval = setInterval(() => {
                if(!hasPlayed && attempts < 120) {
                    tryFetch();
                    attempts++;
                } else {
                    clearInterval(interval);
                }
            }, RETRY_TIMEOUT);
        }, RESPONSE_DELAY);
    });
}

async function loadAndDisplayChatLog(message_log_filename) {
    try {
        const response = await fetch(message_log_filename);
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status} (${message_log_filename})`);
        }

        const chatLog = await response.json();
        chatLog.reverse()

        let formattedHtml = '';
        chatLog.forEach(entry => {
            switch (entry.role) {
                case 'system':
                    break;
                case 'user':
                    formattedHtml += `<div class="message user-message">${entry.content}</div>`;
                    break;
                case 'assistant':
                    formattedHtml += `<div class="message assistant-message">${entry.content}</div>`;
                    break;
                default:
                    formattedHtml += `<div class="message">${entry.content}</div>`;
            }
        });

        document.getElementById('messages').innerHTML = formattedHtml;

    } catch (error) {
        console.error('Failed to load chat log:', error);
    }
}

async function loadAndDisplayEngineLog(engine_log_filename) {
    try {
        const response = await fetch(engine_log_filename);
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status} (${engine_log_filename})`);
        }

        const engineLog = await response.text()

        var lines = engineLog.split('\n').slice(-ENGINE_LOG_LINES_LIMIT);
        lines.reverse();
        var reversedOrderLog = lines.join('\n');

        document.getElementById('engine-log').innerText = reversedOrderLog;

    } catch (error) {
        console.error('Failed to load engine log:', error);
    }    
}

</script>
</body>
</html>
